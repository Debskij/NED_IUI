{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords, genesis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LazyCorpusLoader in module nltk.corpus.util object:\n",
      "\n",
      "wordnet = class LazyCorpusLoader(builtins.object)\n",
      " |  wordnet(name, reader_cls, *args, **kwargs)\n",
      " |  \n",
      " |  To see the API documentation for this lazily loaded corpus, first\n",
      " |  run corpus.ensure_loaded(), and then run help(this_corpus).\n",
      " |  \n",
      " |  LazyCorpusLoader is a proxy object which is used to stand in for a\n",
      " |  corpus object before the corpus is loaded.  This allows NLTK to\n",
      " |  create an object for each corpus, but defer the costs associated\n",
      " |  with loading those corpora until the first time that they're\n",
      " |  actually accessed.\n",
      " |  \n",
      " |  The first time this object is accessed in any way, it will load\n",
      " |  the corresponding corpus, and transform itself into that corpus\n",
      " |  (by modifying its own ``__class__`` and ``__dict__`` attributes).\n",
      " |  \n",
      " |  If the corpus can not be found, then accessing this object will\n",
      " |  raise an exception, displaying installation instructions for the\n",
      " |  NLTK data package.  Once they've properly installed the data\n",
      " |  package (or modified ``nltk.data.path`` to point to its location),\n",
      " |  they can then use the corpus object without restarting python.\n",
      " |  \n",
      " |  :param name: The name of the corpus\n",
      " |  :type name: str\n",
      " |  :param reader_cls: The specific CorpusReader class, e.g. PlaintextCorpusReader, WordListCorpusReader\n",
      " |  :type reader: nltk.corpus.reader.api.CorpusReader\n",
      " |  :param nltk_data_subdir: The subdirectory where the corpus is stored.\n",
      " |  :type nltk_data_subdir: str\n",
      " |  :param `*args`: Any other non-keywords arguments that `reader_cls` might need.\n",
      " |  :param `**kwargs`: Any other keywords arguments that `reader_cls` might need.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, name, reader_cls, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117659\n"
     ]
    }
   ],
   "source": [
    "synsets = list(wn.all_synsets())\n",
    "print(len(synsets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('able.a.01'), Synset('unable.a.01'), Synset('abaxial.a.01'), Synset('adaxial.a.01'), Synset('acroscopic.a.01'), Synset('basiscopic.a.01'), Synset('abducent.a.01'), Synset('adducent.a.01'), Synset('nascent.a.01'), Synset('emergent.s.02')]\n",
      "Help on Synset in module nltk.corpus.reader.wordnet object:\n",
      "\n",
      "class Synset(_WordNetObject)\n",
      " |  Synset(wordnet_corpus_reader)\n",
      " |  \n",
      " |  Create a Synset from a \"<lemma>.<pos>.<number>\" string where:\n",
      " |  <lemma> is the word's morphological stem\n",
      " |  <pos> is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
      " |  <number> is the sense number, counting from 0.\n",
      " |  \n",
      " |  Synset attributes, accessible via methods with the same name:\n",
      " |  \n",
      " |  - name: The canonical name of this synset, formed using the first lemma\n",
      " |    of this synset. Note that this may be different from the name\n",
      " |    passed to the constructor if that string used a different lemma to\n",
      " |    identify the synset.\n",
      " |  - pos: The synset's part of speech, matching one of the module level\n",
      " |    attributes ADJ, ADJ_SAT, ADV, NOUN or VERB.\n",
      " |  - lemmas: A list of the Lemma objects for this synset.\n",
      " |  - definition: The definition for this synset.\n",
      " |  - examples: A list of example strings for this synset.\n",
      " |  - offset: The offset in the WordNet dict file of this synset.\n",
      " |  - lexname: The name of the lexicographer file containing this synset.\n",
      " |  \n",
      " |  Synset methods:\n",
      " |  \n",
      " |  Synsets have the following methods for retrieving related Synsets.\n",
      " |  They correspond to the names for the pointer symbols defined here:\n",
      " |  https://wordnet.princeton.edu/documentation/wninput5wn\n",
      " |  These methods all return lists of Synsets.\n",
      " |  \n",
      " |  - hypernyms, instance_hypernyms\n",
      " |  - hyponyms, instance_hyponyms\n",
      " |  - member_holonyms, substance_holonyms, part_holonyms\n",
      " |  - member_meronyms, substance_meronyms, part_meronyms\n",
      " |  - attributes\n",
      " |  - entailments\n",
      " |  - causes\n",
      " |  - also_sees\n",
      " |  - verb_groups\n",
      " |  - similar_tos\n",
      " |  \n",
      " |  Additionally, Synsets support the following methods specific to the\n",
      " |  hypernym relation:\n",
      " |  \n",
      " |  - root_hypernyms\n",
      " |  - common_hypernyms\n",
      " |  - lowest_common_hypernyms\n",
      " |  \n",
      " |  Note that Synsets do not support the following relations because\n",
      " |  these are defined by WordNet as lexical relations:\n",
      " |  \n",
      " |  - antonyms\n",
      " |  - derivationally_related_forms\n",
      " |  - pertainyms\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Synset\n",
      " |      _WordNetObject\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, wordnet_corpus_reader)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  acyclic_tree = acyclic_depth_first(tree, children=<built-in function iter>, depth=-1, cut_mark=None, traversed=None)\n",
      " |      Traverse the nodes of a tree in depth-first order,\n",
      " |      discarding eventual cycles within any branch,\n",
      " |      adding cut_mark (when specified) if cycles were truncated.\n",
      " |      \n",
      " |      The first argument should be the tree root;\n",
      " |      children should be a function taking as argument a tree node\n",
      " |      and returning an iterator of the node's children.\n",
      " |      \n",
      " |      Catches all cycles:\n",
      " |      \n",
      " |      >>> import nltk\n",
      " |      >>> from nltk.util import acyclic_depth_first as acyclic_tree\n",
      " |      >>> wn=nltk.corpus.wordnet\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> pprint(acyclic_tree(wn.synset('dog.n.01'), lambda s:s.hypernyms(),cut_mark='...'))\n",
      " |      [Synset('dog.n.01'),\n",
      " |       [Synset('canine.n.02'),\n",
      " |        [Synset('carnivore.n.01'),\n",
      " |         [Synset('placental.n.01'),\n",
      " |          [Synset('mammal.n.01'),\n",
      " |           [Synset('vertebrate.n.01'),\n",
      " |            [Synset('chordate.n.01'),\n",
      " |             [Synset('animal.n.01'),\n",
      " |              [Synset('organism.n.01'),\n",
      " |               [Synset('living_thing.n.01'),\n",
      " |                [Synset('whole.n.02'),\n",
      " |                 [Synset('object.n.01'),\n",
      " |                  [Synset('physical_entity.n.01'),\n",
      " |                   [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " |       [Synset('domestic_animal.n.01'), \"Cycle(Synset('animal.n.01'),-3,...)\"]]\n",
      " |  \n",
      " |  closure(self, rel, depth=-1)\n",
      " |      Return the transitive closure of source under the rel\n",
      " |      relationship, breadth-first, discarding cycles:\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> computer = wn.synset('computer.n.01')\n",
      " |      >>> topic = lambda s:s.topic_domains()\n",
      " |      >>> print(list(computer.closure(topic)))\n",
      " |      [Synset('computer_science.n.01')]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('computer.n.01') at depth 2\n",
      " |      \n",
      " |      \n",
      " |      Include redundant paths (but only once), avoiding duplicate searches\n",
      " |      (from 'animal.n.01' to 'entity.n.01'):\n",
      " |      \n",
      " |      >>> dog = wn.synset('dog.n.01')\n",
      " |      >>> hyp = lambda s:s.hypernyms()\n",
      " |      >>> print(list(dog.closure(hyp)))\n",
      " |      [Synset('canine.n.02'), Synset('domestic_animal.n.01'), Synset('carnivore.n.01'),\n",
      " |      Synset('animal.n.01'), Synset('placental.n.01'), Synset('organism.n.01'),\n",
      " |      Synset('mammal.n.01'), Synset('living_thing.n.01'), Synset('vertebrate.n.01'),\n",
      " |      Synset('whole.n.02'), Synset('chordate.n.01'), Synset('object.n.01'),\n",
      " |      Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('animal.n.01') at depth 7\n",
      " |  \n",
      " |  common_hypernyms(self, other)\n",
      " |      Find all synsets that are hypernyms of this synset and the\n",
      " |      other synset.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: other input synset.\n",
      " |      :return: The synsets that are hypernyms of both synsets.\n",
      " |  \n",
      " |  definition(self, lang='eng')\n",
      " |      Return definition in specified language\n",
      " |  \n",
      " |  examples(self, lang='eng')\n",
      " |      Return examples in specified language\n",
      " |  \n",
      " |  frame_ids(self)\n",
      " |  \n",
      " |  hypernym_distances(self, distance=0, simulate_root=False)\n",
      " |      Get the path(s) from this synset to the root, counting the distance\n",
      " |      of each node from the initial node on the way. A set of\n",
      " |      (synset, distance) tuples is returned.\n",
      " |      \n",
      " |      :type distance: int\n",
      " |      :param distance: the distance (number of edges) from this hypernym to\n",
      " |          the original hypernym ``Synset`` on which this method was called.\n",
      " |      :return: A set of ``(Synset, int)`` tuples where each ``Synset`` is\n",
      " |         a hypernym of the first ``Synset``.\n",
      " |  \n",
      " |  hypernym_paths(self)\n",
      " |      Get the path(s) from this synset to the root, where each path is a\n",
      " |      list of the synset nodes traversed on the way to the root.\n",
      " |      \n",
      " |      :return: A list of lists, where each list gives the node sequence\n",
      " |         connecting the initial ``Synset`` node and a root node.\n",
      " |  \n",
      " |  jcn_similarity(self, other, ic, verbose=False)\n",
      " |      Jiang-Conrath Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type  ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects.\n",
      " |  \n",
      " |  lch_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Leacock Chodorow Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses (as above) and the maximum depth\n",
      " |      of the taxonomy in which the senses occur. The relationship is given as\n",
      " |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      " |      depth.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally greater than 0. None is returned if no connecting path\n",
      " |          could be found. If a ``Synset`` is compared with itself, the\n",
      " |          maximum score is returned, which varies depending on the taxonomy\n",
      " |          depth.\n",
      " |  \n",
      " |  lemma_names(self, lang='eng')\n",
      " |      Return all the lemma_names associated with the synset\n",
      " |  \n",
      " |  lemmas(self, lang='eng')\n",
      " |      Return all the lemma objects associated with the synset\n",
      " |  \n",
      " |  lexname(self)\n",
      " |  \n",
      " |  lin_similarity(self, other, ic, verbose=False)\n",
      " |      Lin Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, in the range 0 to 1.\n",
      " |  \n",
      " |  lowest_common_hypernyms(self, other, simulate_root=False, use_min_depth=False)\n",
      " |      Get a list of lowest synset(s) that both synsets have as a hypernym.\n",
      " |      When `use_min_depth == False` this means that the synset which appears\n",
      " |      as a hypernym of both `self` and `other` with the lowest maximum depth\n",
      " |      is returned or if there are multiple such synsets at the same depth\n",
      " |      they are all returned\n",
      " |      \n",
      " |      However, if `use_min_depth == True` then the synset(s) which has/have\n",
      " |      the lowest minimum depth and appear(s) in both paths is/are returned.\n",
      " |      \n",
      " |      By setting the use_min_depth flag to True, the behavior of NLTK2 can be\n",
      " |      preserved. This was changed in NLTK3 to give more accurate results in a\n",
      " |      small set of cases, generally with synsets concerning people. (eg:\n",
      " |      'chef.n.01', 'fireman.n.01', etc.)\n",
      " |      \n",
      " |      This method is an implementation of Ted Pedersen's \"Lowest Common\n",
      " |      Subsumer\" method from the Perl Wordnet module. It can return either\n",
      " |      \"self\" or \"other\" if they are a hypernym of the other.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: other input synset\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (False by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to True to enable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will need to be added\n",
      " |          for nouns as well.\n",
      " |      :type use_min_depth: bool\n",
      " |      :param use_min_depth: This setting mimics older (v2) behavior of NLTK\n",
      " |          wordnet If True, will use the min_depth function to calculate the\n",
      " |          lowest common hypernyms. This is known to give strange results for\n",
      " |          some synset pairs (eg: 'chef.n.01', 'fireman.n.01') but is retained\n",
      " |          for backwards compatibility\n",
      " |      :return: The synsets that are the lowest common hypernyms of both\n",
      " |          synsets\n",
      " |  \n",
      " |  max_depth(self)\n",
      " |      :return: The length of the longest hypernym path from this\n",
      " |          synset to the root.\n",
      " |  \n",
      " |  min_depth(self)\n",
      " |      :return: The length of the shortest hypernym path from this\n",
      " |          synset to the root.\n",
      " |  \n",
      " |  mst = unweighted_minimum_spanning_tree(tree, children=<built-in function iter>)\n",
      " |      Output a Minimum Spanning Tree (MST) of an unweighted graph,\n",
      " |      by traversing the nodes of a tree in breadth-first order,\n",
      " |      discarding eventual cycles.\n",
      " |      \n",
      " |      The first argument should be the tree root;\n",
      " |      children should be a function taking as argument a tree node\n",
      " |      and returning an iterator of the node's children.\n",
      " |      \n",
      " |      >>> import nltk\n",
      " |      >>> from nltk.util import unweighted_minimum_spanning_tree as mst\n",
      " |      >>> wn=nltk.corpus.wordnet\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> pprint(mst(wn.synset('bound.a.01'), lambda s:s.also_sees()))\n",
      " |      [Synset('bound.a.01'),\n",
      " |       [Synset('unfree.a.02'),\n",
      " |        [Synset('confined.a.02')],\n",
      " |        [Synset('dependent.a.01')],\n",
      " |        [Synset('restricted.a.01'), [Synset('classified.a.02')]]]]\n",
      " |  \n",
      " |  name(self)\n",
      " |  \n",
      " |  offset(self)\n",
      " |  \n",
      " |  path_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Path Distance Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      " |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      " |      a path cannot be found (will only be true for verbs as there are many\n",
      " |      distinct verb taxonomies), in which case None is returned. A score of\n",
      " |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally between 0 and 1. None is returned if no connecting path\n",
      " |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      " |          itself.\n",
      " |  \n",
      " |  pos(self)\n",
      " |  \n",
      " |  res_similarity(self, other, ic, verbose=False)\n",
      " |      Resnik Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      " |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      " |  \n",
      " |  root_hypernyms(self)\n",
      " |      Get the topmost hypernyms of this synset in WordNet.\n",
      " |  \n",
      " |  shortest_path_distance(self, other, simulate_root=False)\n",
      " |      Returns the distance of the shortest path linking the two synsets (if\n",
      " |      one exists). For each synset, all the ancestor nodes and their\n",
      " |      distances are recorded and compared. The ancestor node common to both\n",
      " |      synsets that can be reached with the minimum number of traversals is\n",
      " |      used. If no ancestor nodes are common, None is returned. If a node is\n",
      " |      compared with itself 0 is returned.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The Synset to which the shortest path will be found.\n",
      " |      :return: The number of edges in the shortest path connecting the two\n",
      " |          nodes, or None if no path exists.\n",
      " |  \n",
      " |  tree(self, rel, depth=-1, cut_mark=None)\n",
      " |      Return the full relation tree, including self,\n",
      " |      discarding cycles:\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> computer = wn.synset('computer.n.01')\n",
      " |      >>> topic = lambda s:s.topic_domains()\n",
      " |      >>> pprint(computer.tree(topic))\n",
      " |      [Synset('computer.n.01'), [Synset('computer_science.n.01')]]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('computer.n.01') at depth -3\n",
      " |      \n",
      " |      \n",
      " |      But keep duplicate branches (from 'animal.n.01' to 'entity.n.01'):\n",
      " |      \n",
      " |      >>> dog = wn.synset('dog.n.01')\n",
      " |      >>> hyp = lambda s:s.hypernyms()\n",
      " |      >>> pprint(dog.tree(hyp))\n",
      " |      [Synset('dog.n.01'),\n",
      " |       [Synset('canine.n.02'),\n",
      " |        [Synset('carnivore.n.01'),\n",
      " |         [Synset('placental.n.01'),\n",
      " |          [Synset('mammal.n.01'),\n",
      " |           [Synset('vertebrate.n.01'),\n",
      " |            [Synset('chordate.n.01'),\n",
      " |             [Synset('animal.n.01'),\n",
      " |              [Synset('organism.n.01'),\n",
      " |               [Synset('living_thing.n.01'),\n",
      " |                [Synset('whole.n.02'),\n",
      " |                 [Synset('object.n.01'),\n",
      " |                  [Synset('physical_entity.n.01'),\n",
      " |                   [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " |       [Synset('domestic_animal.n.01'),\n",
      " |        [Synset('animal.n.01'),\n",
      " |         [Synset('organism.n.01'),\n",
      " |          [Synset('living_thing.n.01'),\n",
      " |           [Synset('whole.n.02'),\n",
      " |            [Synset('object.n.01'),\n",
      " |             [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]\n",
      " |  \n",
      " |  wup_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Wu-Palmer Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      depth of the two senses in the taxonomy and that of their Least Common\n",
      " |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      " |      by this implementation did _not_ always agree with those given by\n",
      " |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      " |      the addition of the simulate_root flag (see below), the score for\n",
      " |      verbs now almost always agree but not always for nouns.\n",
      " |      \n",
      " |      The LCS does not necessarily feature in the shortest path connecting\n",
      " |      the two senses, as it is by definition the common ancestor deepest in\n",
      " |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      " |      will so feature. Where multiple candidates for the LCS exist, that\n",
      " |      whose shortest path to the root node is the longest will be selected.\n",
      " |      Where the LCS has multiple paths to the root, the longer path is used\n",
      " |      for the purposes of the calculation.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, normally greater than zero. If no connecting path between\n",
      " |          the two senses can be found, None is returned.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _WordNetObject:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      " |  \n",
      " |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  also_sees(self)\n",
      " |  \n",
      " |  attributes(self)\n",
      " |  \n",
      " |  causes(self)\n",
      " |  \n",
      " |  entailments(self)\n",
      " |  \n",
      " |  hypernyms(self)\n",
      " |  \n",
      " |  hyponyms(self)\n",
      " |  \n",
      " |  in_region_domains(self)\n",
      " |  \n",
      " |  in_topic_domains(self)\n",
      " |  \n",
      " |  in_usage_domains(self)\n",
      " |  \n",
      " |  instance_hypernyms(self)\n",
      " |  \n",
      " |  instance_hyponyms(self)\n",
      " |  \n",
      " |  member_holonyms(self)\n",
      " |  \n",
      " |  member_meronyms(self)\n",
      " |  \n",
      " |  part_holonyms(self)\n",
      " |  \n",
      " |  part_meronyms(self)\n",
      " |  \n",
      " |  region_domains(self)\n",
      " |  \n",
      " |  similar_tos(self)\n",
      " |  \n",
      " |  substance_holonyms(self)\n",
      " |  \n",
      " |  substance_meronyms(self)\n",
      " |  \n",
      " |  topic_domains(self)\n",
      " |  \n",
      " |  usage_domains(self)\n",
      " |  \n",
      " |  verb_groups(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _WordNetObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(synsets[:10])\n",
    "help(synsets[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "e = wn.synsets(\"dog\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "21\n",
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds {Synset('animal.n.01')}\n",
      "a dull unattractive unpleasant girl or woman {Synset('unpleasant_person.n.01')}\n",
      "informal term for a man {Synset('causal_agent.n.01'), Synset('male.n.02')}\n",
      "someone who is morally reprehensible {Synset('villain.n.01')}\n",
      "a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll {Synset('matter.n.03')}\n",
      "a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward {Synset('restraint.n.06')}\n",
      "metal supports for logs in a fireplace {Synset('support.n.10')}\n"
     ]
    }
   ],
   "source": [
    "def find_highest_uncommon_ancestors(word, noun_only = True):\n",
    "    if noun_only:\n",
    "        synsets = wn.synsets(word, pos=wn.NOUN)\n",
    "    else:\n",
    "        # TODO\n",
    "        synsets = wn.synsets(word)\n",
    "    print(len(synsets))\n",
    "    synsets_lca = {syn: set() for syn in synsets}\n",
    "    possible_relations = list(itertools.combinations(synsets, 2))\n",
    "    print(len(possible_relations))\n",
    "    for a, b in possible_relations:\n",
    "        lch = a.lowest_common_hypernyms(b)\n",
    "        synsets_lca[a].add(lch[0])\n",
    "        synsets_lca[b].add(lch[0])\n",
    "    synsets_hua = dict()\n",
    "    for synset in synsets:\n",
    "        tree = synset.tree(lambda s:s.hypernyms())\n",
    "        current_entity = tree[0]\n",
    "        trees = tree[1:]\n",
    "        synsets_hua[synset] = highest_uncommon_ancestor(trees, synsets_lca[synset])\n",
    "    return synsets_hua\n",
    "\n",
    "def highest_uncommon_ancestor(trees, synsets_lca):\n",
    "    ua_list = set()\n",
    "    for further_tree in trees:\n",
    "        while True:\n",
    "            next_entity = further_tree[0]\n",
    "            further_tree = further_tree[1:]\n",
    "            if len(further_tree) > 1:\n",
    "                ua_list.update(highest_uncommon_ancestor(further_tree, synsets_lca))\n",
    "            else:\n",
    "                further_tree = further_tree[0]\n",
    "            if next_entity not in synsets_lca:\n",
    "                current_entity = next_entity\n",
    "            else:\n",
    "                ua_list.add(current_entity)\n",
    "                break\n",
    "    return ua_list\n",
    "\n",
    "hua = find_highest_uncommon_ancestors(\"dog\")\n",
    "for k, v in hua.items():\n",
    "    print(k.definition(), v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "examples_count = np.array([len(synset.examples()) for synset in synsets])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "48339"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = np.array([(synset, len(synset.examples())) for synset in synsets])\n",
    "new_examples = examples[examples[:,1]>0]\n",
    "np.sum(new_examples[:,1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cheeseparing.s.01') ['our cheeseparing administration', 'very close (or near) with his money', 'a penny-pinching miserly old man']\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "e = choice(new_examples)[0]\n",
    "print(e, e.examples())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "48224"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "len(set(list(itertools.chain(*[x.examples() for x in synsets]))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('entity.n.01')]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domestic_animal = wn.synsets('dog')[0].hypernyms()[1]\n",
    "animal = domestic_animal.hypernyms()[0]\n",
    "domestic_animal.root_hypernyms()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('domestic_animal.n.01'),\n [Synset('animal.n.01'),\n  [Synset('organism.n.01'), [Synset('living_thing.n.01')]]]]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domestic_animal.tree(lambda s:s.hypernyms(), depth=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "animal.tree(lambda s:s.hypernyms())\n",
    "\n",
    "mouse = wn.synsets('mouse')[0]\n",
    "prey_animal = wn.synsets('prey')[1]\n",
    "prey_human = wn.synsets('prey')[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('organism.n.01')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_human.lowest_common_hypernyms(prey_animal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('mouse.n.01'),\n [Synset('rodent.n.01'),\n  [Synset('placental.n.01'),\n   [Synset('mammal.n.01'),\n    [Synset('vertebrate.n.01'),\n     [Synset('chordate.n.01'),\n      [Synset('animal.n.01'),\n       [Synset('organism.n.01'),\n        [Synset('living_thing.n.01'),\n         [Synset('whole.n.02'),\n          [Synset('object.n.01'),\n           [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]]]]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse.tree(lambda s:s.hypernyms())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_animal.tree(lambda s:s.hypernyms())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('prey.n.01'),\n [Synset('victim.n.01'),\n  [Synset('unfortunate.n.01'),\n   [Synset('person.n.01'),\n    [Synset('causal_agent.n.01'),\n     [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]],\n    [Synset('organism.n.01'),\n     [Synset('living_thing.n.01'),\n      [Synset('whole.n.02'),\n       [Synset('object.n.01'),\n        [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_human.tree(lambda s:s.hypernyms())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Synset in module nltk.corpus.reader.wordnet object:\n",
      "\n",
      "class Synset(_WordNetObject)\n",
      " |  Synset(wordnet_corpus_reader)\n",
      " |  \n",
      " |  Create a Synset from a \"<lemma>.<pos>.<number>\" string where:\n",
      " |  <lemma> is the word's morphological stem\n",
      " |  <pos> is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
      " |  <number> is the sense number, counting from 0.\n",
      " |  \n",
      " |  Synset attributes, accessible via methods with the same name:\n",
      " |  \n",
      " |  - name: The canonical name of this synset, formed using the first lemma\n",
      " |    of this synset. Note that this may be different from the name\n",
      " |    passed to the constructor if that string used a different lemma to\n",
      " |    identify the synset.\n",
      " |  - pos: The synset's part of speech, matching one of the module level\n",
      " |    attributes ADJ, ADJ_SAT, ADV, NOUN or VERB.\n",
      " |  - lemmas: A list of the Lemma objects for this synset.\n",
      " |  - definition: The definition for this synset.\n",
      " |  - examples: A list of example strings for this synset.\n",
      " |  - offset: The offset in the WordNet dict file of this synset.\n",
      " |  - lexname: The name of the lexicographer file containing this synset.\n",
      " |  \n",
      " |  Synset methods:\n",
      " |  \n",
      " |  Synsets have the following methods for retrieving related Synsets.\n",
      " |  They correspond to the names for the pointer symbols defined here:\n",
      " |  https://wordnet.princeton.edu/documentation/wninput5wn\n",
      " |  These methods all return lists of Synsets.\n",
      " |  \n",
      " |  - hypernyms, instance_hypernyms\n",
      " |  - hyponyms, instance_hyponyms\n",
      " |  - member_holonyms, substance_holonyms, part_holonyms\n",
      " |  - member_meronyms, substance_meronyms, part_meronyms\n",
      " |  - attributes\n",
      " |  - entailments\n",
      " |  - causes\n",
      " |  - also_sees\n",
      " |  - verb_groups\n",
      " |  - similar_tos\n",
      " |  \n",
      " |  Additionally, Synsets support the following methods specific to the\n",
      " |  hypernym relation:\n",
      " |  \n",
      " |  - root_hypernyms\n",
      " |  - common_hypernyms\n",
      " |  - lowest_common_hypernyms\n",
      " |  \n",
      " |  Note that Synsets do not support the following relations because\n",
      " |  these are defined by WordNet as lexical relations:\n",
      " |  \n",
      " |  - antonyms\n",
      " |  - derivationally_related_forms\n",
      " |  - pertainyms\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Synset\n",
      " |      _WordNetObject\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, wordnet_corpus_reader)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  acyclic_tree = acyclic_depth_first(tree, children=<built-in function iter>, depth=-1, cut_mark=None, traversed=None)\n",
      " |      Traverse the nodes of a tree in depth-first order,\n",
      " |      discarding eventual cycles within any branch,\n",
      " |      adding cut_mark (when specified) if cycles were truncated.\n",
      " |      \n",
      " |      The first argument should be the tree root;\n",
      " |      children should be a function taking as argument a tree node\n",
      " |      and returning an iterator of the node's children.\n",
      " |      \n",
      " |      Catches all cycles:\n",
      " |      \n",
      " |      >>> import nltk\n",
      " |      >>> from nltk.util import acyclic_depth_first as acyclic_tree\n",
      " |      >>> wn=nltk.corpus.wordnet\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> pprint(acyclic_tree(wn.synset('dog.n.01'), lambda s:s.hypernyms(),cut_mark='...'))\n",
      " |      [Synset('dog.n.01'),\n",
      " |       [Synset('canine.n.02'),\n",
      " |        [Synset('carnivore.n.01'),\n",
      " |         [Synset('placental.n.01'),\n",
      " |          [Synset('mammal.n.01'),\n",
      " |           [Synset('vertebrate.n.01'),\n",
      " |            [Synset('chordate.n.01'),\n",
      " |             [Synset('animal.n.01'),\n",
      " |              [Synset('organism.n.01'),\n",
      " |               [Synset('living_thing.n.01'),\n",
      " |                [Synset('whole.n.02'),\n",
      " |                 [Synset('object.n.01'),\n",
      " |                  [Synset('physical_entity.n.01'),\n",
      " |                   [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " |       [Synset('domestic_animal.n.01'), \"Cycle(Synset('animal.n.01'),-3,...)\"]]\n",
      " |  \n",
      " |  closure(self, rel, depth=-1)\n",
      " |      Return the transitive closure of source under the rel\n",
      " |      relationship, breadth-first, discarding cycles:\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> computer = wn.synset('computer.n.01')\n",
      " |      >>> topic = lambda s:s.topic_domains()\n",
      " |      >>> print(list(computer.closure(topic)))\n",
      " |      [Synset('computer_science.n.01')]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('computer.n.01') at depth 2\n",
      " |      \n",
      " |      \n",
      " |      Include redundant paths (but only once), avoiding duplicate searches\n",
      " |      (from 'animal.n.01' to 'entity.n.01'):\n",
      " |      \n",
      " |      >>> dog = wn.synset('dog.n.01')\n",
      " |      >>> hyp = lambda s:s.hypernyms()\n",
      " |      >>> print(list(dog.closure(hyp)))\n",
      " |      [Synset('canine.n.02'), Synset('domestic_animal.n.01'), Synset('carnivore.n.01'),\n",
      " |      Synset('animal.n.01'), Synset('placental.n.01'), Synset('organism.n.01'),\n",
      " |      Synset('mammal.n.01'), Synset('living_thing.n.01'), Synset('vertebrate.n.01'),\n",
      " |      Synset('whole.n.02'), Synset('chordate.n.01'), Synset('object.n.01'),\n",
      " |      Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('animal.n.01') at depth 7\n",
      " |  \n",
      " |  common_hypernyms(self, other)\n",
      " |      Find all synsets that are hypernyms of this synset and the\n",
      " |      other synset.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: other input synset.\n",
      " |      :return: The synsets that are hypernyms of both synsets.\n",
      " |  \n",
      " |  definition(self, lang='eng')\n",
      " |      Return definition in specified language\n",
      " |  \n",
      " |  examples(self, lang='eng')\n",
      " |      Return examples in specified language\n",
      " |  \n",
      " |  frame_ids(self)\n",
      " |  \n",
      " |  hypernym_distances(self, distance=0, simulate_root=False)\n",
      " |      Get the path(s) from this synset to the root, counting the distance\n",
      " |      of each node from the initial node on the way. A set of\n",
      " |      (synset, distance) tuples is returned.\n",
      " |      \n",
      " |      :type distance: int\n",
      " |      :param distance: the distance (number of edges) from this hypernym to\n",
      " |          the original hypernym ``Synset`` on which this method was called.\n",
      " |      :return: A set of ``(Synset, int)`` tuples where each ``Synset`` is\n",
      " |         a hypernym of the first ``Synset``.\n",
      " |  \n",
      " |  hypernym_paths(self)\n",
      " |      Get the path(s) from this synset to the root, where each path is a\n",
      " |      list of the synset nodes traversed on the way to the root.\n",
      " |      \n",
      " |      :return: A list of lists, where each list gives the node sequence\n",
      " |         connecting the initial ``Synset`` node and a root node.\n",
      " |  \n",
      " |  jcn_similarity(self, other, ic, verbose=False)\n",
      " |      Jiang-Conrath Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type  ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects.\n",
      " |  \n",
      " |  lch_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Leacock Chodorow Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses (as above) and the maximum depth\n",
      " |      of the taxonomy in which the senses occur. The relationship is given as\n",
      " |      -log(p/2d) where p is the shortest path length and d is the taxonomy\n",
      " |      depth.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally greater than 0. None is returned if no connecting path\n",
      " |          could be found. If a ``Synset`` is compared with itself, the\n",
      " |          maximum score is returned, which varies depending on the taxonomy\n",
      " |          depth.\n",
      " |  \n",
      " |  lemma_names(self, lang='eng')\n",
      " |      Return all the lemma_names associated with the synset\n",
      " |  \n",
      " |  lemmas(self, lang='eng')\n",
      " |      Return all the lemma objects associated with the synset\n",
      " |  \n",
      " |  lexname(self)\n",
      " |  \n",
      " |  lin_similarity(self, other, ic, verbose=False)\n",
      " |      Lin Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node) and that of the two input Synsets. The relationship is\n",
      " |      given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, in the range 0 to 1.\n",
      " |  \n",
      " |  lowest_common_hypernyms(self, other, simulate_root=False, use_min_depth=False)\n",
      " |      Get a list of lowest synset(s) that both synsets have as a hypernym.\n",
      " |      When `use_min_depth == False` this means that the synset which appears\n",
      " |      as a hypernym of both `self` and `other` with the lowest maximum depth\n",
      " |      is returned or if there are multiple such synsets at the same depth\n",
      " |      they are all returned\n",
      " |      \n",
      " |      However, if `use_min_depth == True` then the synset(s) which has/have\n",
      " |      the lowest minimum depth and appear(s) in both paths is/are returned.\n",
      " |      \n",
      " |      By setting the use_min_depth flag to True, the behavior of NLTK2 can be\n",
      " |      preserved. This was changed in NLTK3 to give more accurate results in a\n",
      " |      small set of cases, generally with synsets concerning people. (eg:\n",
      " |      'chef.n.01', 'fireman.n.01', etc.)\n",
      " |      \n",
      " |      This method is an implementation of Ted Pedersen's \"Lowest Common\n",
      " |      Subsumer\" method from the Perl Wordnet module. It can return either\n",
      " |      \"self\" or \"other\" if they are a hypernym of the other.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: other input synset\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (False by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to True to enable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will need to be added\n",
      " |          for nouns as well.\n",
      " |      :type use_min_depth: bool\n",
      " |      :param use_min_depth: This setting mimics older (v2) behavior of NLTK\n",
      " |          wordnet If True, will use the min_depth function to calculate the\n",
      " |          lowest common hypernyms. This is known to give strange results for\n",
      " |          some synset pairs (eg: 'chef.n.01', 'fireman.n.01') but is retained\n",
      " |          for backwards compatibility\n",
      " |      :return: The synsets that are the lowest common hypernyms of both\n",
      " |          synsets\n",
      " |  \n",
      " |  max_depth(self)\n",
      " |      :return: The length of the longest hypernym path from this\n",
      " |          synset to the root.\n",
      " |  \n",
      " |  min_depth(self)\n",
      " |      :return: The length of the shortest hypernym path from this\n",
      " |          synset to the root.\n",
      " |  \n",
      " |  mst = unweighted_minimum_spanning_tree(tree, children=<built-in function iter>)\n",
      " |      Output a Minimum Spanning Tree (MST) of an unweighted graph,\n",
      " |      by traversing the nodes of a tree in breadth-first order,\n",
      " |      discarding eventual cycles.\n",
      " |      \n",
      " |      The first argument should be the tree root;\n",
      " |      children should be a function taking as argument a tree node\n",
      " |      and returning an iterator of the node's children.\n",
      " |      \n",
      " |      >>> import nltk\n",
      " |      >>> from nltk.util import unweighted_minimum_spanning_tree as mst\n",
      " |      >>> wn=nltk.corpus.wordnet\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> pprint(mst(wn.synset('bound.a.01'), lambda s:s.also_sees()))\n",
      " |      [Synset('bound.a.01'),\n",
      " |       [Synset('unfree.a.02'),\n",
      " |        [Synset('confined.a.02')],\n",
      " |        [Synset('dependent.a.01')],\n",
      " |        [Synset('restricted.a.01'), [Synset('classified.a.02')]]]]\n",
      " |  \n",
      " |  name(self)\n",
      " |  \n",
      " |  offset(self)\n",
      " |  \n",
      " |  path_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Path Distance Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
      " |      taxonomy. The score is in the range 0 to 1, except in those cases where\n",
      " |      a path cannot be found (will only be true for verbs as there are many\n",
      " |      distinct verb taxonomies), in which case None is returned. A score of\n",
      " |      1 represents identity i.e. comparing a sense with itself will return 1.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A score denoting the similarity of the two ``Synset`` objects,\n",
      " |          normally between 0 and 1. None is returned if no connecting path\n",
      " |          could be found. 1 is returned if a ``Synset`` is compared with\n",
      " |          itself.\n",
      " |  \n",
      " |  pos(self)\n",
      " |  \n",
      " |  res_similarity(self, other, ic, verbose=False)\n",
      " |      Resnik Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      Information Content (IC) of the Least Common Subsumer (most specific\n",
      " |      ancestor node).\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type ic: dict\n",
      " |      :param ic: an information content object (as returned by\n",
      " |          ``nltk.corpus.wordnet_ic.ic()``).\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects. Synsets whose LCS is the root node of the taxonomy will\n",
      " |          have a score of 0 (e.g. N['dog'][0] and N['table'][0]).\n",
      " |  \n",
      " |  root_hypernyms(self)\n",
      " |      Get the topmost hypernyms of this synset in WordNet.\n",
      " |  \n",
      " |  shortest_path_distance(self, other, simulate_root=False)\n",
      " |      Returns the distance of the shortest path linking the two synsets (if\n",
      " |      one exists). For each synset, all the ancestor nodes and their\n",
      " |      distances are recorded and compared. The ancestor node common to both\n",
      " |      synsets that can be reached with the minimum number of traversals is\n",
      " |      used. If no ancestor nodes are common, None is returned. If a node is\n",
      " |      compared with itself 0 is returned.\n",
      " |      \n",
      " |      :type other: Synset\n",
      " |      :param other: The Synset to which the shortest path will be found.\n",
      " |      :return: The number of edges in the shortest path connecting the two\n",
      " |          nodes, or None if no path exists.\n",
      " |  \n",
      " |  tree(self, rel, depth=-1, cut_mark=None)\n",
      " |      Return the full relation tree, including self,\n",
      " |      discarding cycles:\n",
      " |      \n",
      " |      >>> from nltk.corpus import wordnet as wn\n",
      " |      >>> from pprint import pprint\n",
      " |      >>> computer = wn.synset('computer.n.01')\n",
      " |      >>> topic = lambda s:s.topic_domains()\n",
      " |      >>> pprint(computer.tree(topic))\n",
      " |      [Synset('computer.n.01'), [Synset('computer_science.n.01')]]\n",
      " |      \n",
      " |      UserWarning: Discarded redundant search for Synset('computer.n.01') at depth -3\n",
      " |      \n",
      " |      \n",
      " |      But keep duplicate branches (from 'animal.n.01' to 'entity.n.01'):\n",
      " |      \n",
      " |      >>> dog = wn.synset('dog.n.01')\n",
      " |      >>> hyp = lambda s:s.hypernyms()\n",
      " |      >>> pprint(dog.tree(hyp))\n",
      " |      [Synset('dog.n.01'),\n",
      " |       [Synset('canine.n.02'),\n",
      " |        [Synset('carnivore.n.01'),\n",
      " |         [Synset('placental.n.01'),\n",
      " |          [Synset('mammal.n.01'),\n",
      " |           [Synset('vertebrate.n.01'),\n",
      " |            [Synset('chordate.n.01'),\n",
      " |             [Synset('animal.n.01'),\n",
      " |              [Synset('organism.n.01'),\n",
      " |               [Synset('living_thing.n.01'),\n",
      " |                [Synset('whole.n.02'),\n",
      " |                 [Synset('object.n.01'),\n",
      " |                  [Synset('physical_entity.n.01'),\n",
      " |                   [Synset('entity.n.01')]]]]]]]]]]]]],\n",
      " |       [Synset('domestic_animal.n.01'),\n",
      " |        [Synset('animal.n.01'),\n",
      " |         [Synset('organism.n.01'),\n",
      " |          [Synset('living_thing.n.01'),\n",
      " |           [Synset('whole.n.02'),\n",
      " |            [Synset('object.n.01'),\n",
      " |             [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]\n",
      " |  \n",
      " |  wup_similarity(self, other, verbose=False, simulate_root=True)\n",
      " |      Wu-Palmer Similarity:\n",
      " |      Return a score denoting how similar two word senses are, based on the\n",
      " |      depth of the two senses in the taxonomy and that of their Least Common\n",
      " |      Subsumer (most specific ancestor node). Previously, the scores computed\n",
      " |      by this implementation did _not_ always agree with those given by\n",
      " |      Pedersen's Perl implementation of WordNet Similarity. However, with\n",
      " |      the addition of the simulate_root flag (see below), the score for\n",
      " |      verbs now almost always agree but not always for nouns.\n",
      " |      \n",
      " |      The LCS does not necessarily feature in the shortest path connecting\n",
      " |      the two senses, as it is by definition the common ancestor deepest in\n",
      " |      the taxonomy, not closest to the two senses. Typically, however, it\n",
      " |      will so feature. Where multiple candidates for the LCS exist, that\n",
      " |      whose shortest path to the root node is the longest will be selected.\n",
      " |      Where the LCS has multiple paths to the root, the longer path is used\n",
      " |      for the purposes of the calculation.\n",
      " |      \n",
      " |      :type  other: Synset\n",
      " |      :param other: The ``Synset`` that this ``Synset`` is being compared to.\n",
      " |      :type simulate_root: bool\n",
      " |      :param simulate_root: The various verb taxonomies do not\n",
      " |          share a single root which disallows this metric from working for\n",
      " |          synsets that are not connected. This flag (True by default)\n",
      " |          creates a fake root that connects all the taxonomies. Set it\n",
      " |          to false to disable this behavior. For the noun taxonomy,\n",
      " |          there is usually a default root except for WordNet version 1.6.\n",
      " |          If you are using wordnet 1.6, a fake root will be added for nouns\n",
      " |          as well.\n",
      " |      :return: A float score denoting the similarity of the two ``Synset``\n",
      " |          objects, normally greater than zero. If no connecting path between\n",
      " |          the two senses can be found, None is returned.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _WordNetObject:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      " |  \n",
      " |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  also_sees(self)\n",
      " |  \n",
      " |  attributes(self)\n",
      " |  \n",
      " |  causes(self)\n",
      " |  \n",
      " |  entailments(self)\n",
      " |  \n",
      " |  hypernyms(self)\n",
      " |  \n",
      " |  hyponyms(self)\n",
      " |  \n",
      " |  in_region_domains(self)\n",
      " |  \n",
      " |  in_topic_domains(self)\n",
      " |  \n",
      " |  in_usage_domains(self)\n",
      " |  \n",
      " |  instance_hypernyms(self)\n",
      " |  \n",
      " |  instance_hyponyms(self)\n",
      " |  \n",
      " |  member_holonyms(self)\n",
      " |  \n",
      " |  member_meronyms(self)\n",
      " |  \n",
      " |  part_holonyms(self)\n",
      " |  \n",
      " |  part_meronyms(self)\n",
      " |  \n",
      " |  region_domains(self)\n",
      " |  \n",
      " |  similar_tos(self)\n",
      " |  \n",
      " |  substance_holonyms(self)\n",
      " |  \n",
      " |  substance_meronyms(self)\n",
      " |  \n",
      " |  topic_domains(self)\n",
      " |  \n",
      " |  usage_domains(self)\n",
      " |  \n",
      " |  verb_groups(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _WordNetObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(prey_human)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
